{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-Captioning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML+ylqF7RKvIyUgLcJZ/Vi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malraharsh/Image-Captioning/blob/master/Image_Captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCy5drHUDkrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsJD2Ic4DmxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
        "\n",
        "!unzip Flickr8k_Dataset.zip\n",
        "\n",
        "!mkdir textFiles\n",
        "!unzip Flickr8k_text.zip -d /content/textFiles\n",
        "\n",
        "!rm -r sample_data\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnSJhaMDGBoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import glob\n",
        "\n",
        "# for i in glob.glob('*.txt'):\n",
        "#     !rm $i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbqmS00PJgxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_file(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwH8qoRVHIh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = load_file('/content/textFiles/Flickr8k.token.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwVo-E6IC8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cffc099f-adad-4d1c-8852-f32b0d73d466"
      },
      "source": [
        "print(doc[:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
            "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
            "1000268201_693b08cb0e.jpg#2\tA lit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh3dw0EOJ6Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_descriptions(file):\n",
        "    info = {}\n",
        "\n",
        "    for line in file.split('\\n'):\n",
        "        if len(line) <= 1:\n",
        "            continue\n",
        "        \n",
        "        img_id, img_descr = line.split('\\t')\n",
        "\n",
        "        img_id = img_id.split('.')[0]\n",
        "\n",
        "        if img_id not in info:\n",
        "            info[img_id] = list()\n",
        "        info[img_id].append(img_descr)\n",
        "\n",
        "    return info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtHp5xE5LPQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "167ace5d-af12-40ca-9a02-bcf0a7b4eb9c"
      },
      "source": [
        "descriptions = load_descriptions(doc)\n",
        "list(descriptions.items())[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1000268201_693b08cb0e',\n",
              "  ['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
              "   'A girl going into a wooden building .',\n",
              "   'A little girl climbing into a wooden playhouse .',\n",
              "   'A little girl climbing the stairs to her playhouse .',\n",
              "   'A little girl in a pink dress going into a wooden cabin .']),\n",
              " ('1001773457_577c3a7d70',\n",
              "  ['A black dog and a spotted dog are fighting',\n",
              "   'A black dog and a tri-colored dog playing with each other on the road .',\n",
              "   'A black dog and a white dog with brown spots are staring at each other in the street .',\n",
              "   'Two dogs of different breeds looking at each other on the road .',\n",
              "   'Two dogs on pavement moving toward each other .']),\n",
              " ('1002674143_1b742ab4b8',\n",
              "  ['A little girl covered in paint sits in front of a painted rainbow with her hands in a bowl .',\n",
              "   'A little girl is sitting in front of a large painted rainbow .',\n",
              "   'A small girl in the grass plays with fingerpaints in front of a white canvas with a rainbow on it .',\n",
              "   'There is a girl with pigtails sitting in front of a rainbow painting .',\n",
              "   'Young girl with pigtails painting outside in the grass .'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fLyX_SbL_vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n = 3\n",
        "# i = 0\n",
        "\n",
        "# fix, ax = plt.subplots(n, 1, figsize=(25, 25))\n",
        "# # ax.flatten()\n",
        "\n",
        "# for (img_filename, img_descr) in list(descriptions.items())[:n]:\n",
        "#     img_file = plt.imread('/content/Flicker8k_Dataset/' + img_filename + '.jpg')\n",
        "#     ax[i].imshow(img_file)\n",
        "#     print(' /n'.join(img_descr))\n",
        "#     i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQVgHNAUYpVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1eda47a1-eb8e-4285-bdef-95934fc51f69"
      },
      "source": [
        "# import nltk\n",
        "# from nltk.corpus import stopwords\n",
        "# nltk.download('stopwords')\n",
        "# print(stopwords.words('english'))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP5IqPGhO-ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_sentence(sent):\n",
        "    words = sent.split()\n",
        "    words = map(str.lower, words)\n",
        "    words = [w for w in words if len(w) > 1]\n",
        "    words = [w for w in words if w.isalpha()] \n",
        "    return ' '.join(words)\n",
        "\n",
        "def clean_descriptions(file):\n",
        "    table = str.maketrans('', '', string.punctuation) #intab, outtab, toremove string, outtab replace intab\n",
        "\n",
        "    for key, desc_list in descriptions.items():\n",
        "        for idx, desc in enumerate(desc_list):\n",
        "            desc_list[idx] = clean_sentence(desc)\n",
        "\n",
        "clean_descriptions(descriptions)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qd0dm-lfalG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "672ed3f5-e693-467a-d489-0b8e899c4562"
      },
      "source": [
        "descriptions['1001773457_577c3a7d70']"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['black dog and spotted dog are fighting',\n",
              " 'black dog and dog playing with each other on the road',\n",
              " 'black dog and white dog with brown spots are staring at each other in the street',\n",
              " 'two dogs of different breeds looking at each other on the road',\n",
              " 'two dogs on pavement moving toward each other']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vY37Wv4hzps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9c48520d-a087-4b9e-fea4-7187abffd381"
      },
      "source": [
        "list(descriptions.items())[:1]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1000268201_693b08cb0e',\n",
              "  ['child in pink dress is climbing up set of stairs in an entry way',\n",
              "   'girl going into wooden building',\n",
              "   'little girl climbing into wooden playhouse',\n",
              "   'little girl climbing the stairs to her playhouse',\n",
              "   'little girl in pink dress going into wooden cabin'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsNqyE49iUys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d6b9017-41cc-4b7f-fb50-ad1ad30424d9"
      },
      "source": [
        "def create_vocab(descr):\n",
        "    vocab = set()\n",
        "\n",
        "    for d_list in descr.values():\n",
        "        [vocab.update(d.split()) for d in d_list]\n",
        "\n",
        "    return vocab\n",
        "\n",
        "vocabulary = create_vocab(descriptions)\n",
        "list(vocabulary)[:5]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lifting', 'runner', 'graphic', 'padding', 'greyish']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTS6bDpAjEij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "json.dump(descriptions, open('descriptions.txt', 'w'))\n",
        "# json.load(descriptions, open('descriptions.txt', 'r'))"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG7D6tj9jGp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_img_data = '/content/Flicker8k_Dataset/'\n",
        "path_text = '/content/textFiles/'"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XvcaMcwyDLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/Flicker8k_Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH1AYLlCyEPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_path = load_file('/content/textFiles/Flickr_8k.trainImages.txt')\n",
        "test_images_path = load_file('/content/textFiles/Flickr_8k.testImages.txt')"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuiFPLALz6pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_images_list(imgnames, source=path_img_data):\n",
        "    images = list()\n",
        "\n",
        "    for img in imgnames:\n",
        "        images.append(source+img)\n",
        "\n",
        "    return images\n",
        "\n",
        "train_images = create_images_list(train_images_path)\n",
        "test_images = create_images_list(test_images_path)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJOlabd11FHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "img_shape = (299, 299)\n",
        "\n",
        "def preprocess(img_path):\n",
        "    img = Image.load_img(img_path, target_size=img_shape)\n",
        "    img = Image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZTkaH7O2kw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "303b0c52-0013-414d-c8c4-8ee09af43f9f"
      },
      "source": [
        "import glob\n",
        "from pickle import dump, load\n",
        "from time import time\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.merge import add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSpXLx8q7sPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "64c99a95-b87d-46a0-bd54-1e8e42d0aeee"
      },
      "source": [
        "model = InceptionV3(weights='imagenet')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He58ZLEn-t-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}