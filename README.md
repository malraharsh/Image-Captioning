# Image Captioning using LSTM with Flickr data
### Making images speak
This repo contains my work regarding the project image captioning. 

The aim of my project is to take any image provided by the user, and then use my trained model to describe the current event of the image. This is the implementation of model using LSTM and Dense layers to process then input and then combine them to predict the next work for our caption use Deep learning methods.

## Getting Started

### Prerequisites
1. **Python 3** 
2. **Python libraries**: numpy, pandas, scipy, matplotlib, keras, tensorflow 


### Download the dataset

You have two possibilities:

1. The flickr8k dataset used in this project has been downloaded from: [Flickr8k_Dataset.zip]
(https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip)

2. Download the caption from [here](https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip
).


### Launch Jupyter Notebook



https://github.com/hlamba28/Automatic-Image-Captioning/blob/master/Automatic%20Image%20Captioning.ipynb

https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8
